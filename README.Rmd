---
title: "Introduction to the baserater package"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to the baserater package}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

The `baserater` package allows to:
- Download LLM‑generated stereotype datasets and human validation ratings from the original paper
- Generate new typicality scores with any Hugging Face model
- Benchmark new scores against human ground truth and strong LLM baselines
- Build base‑rate stereotype tables from typicality matrices

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment  = "#>",
  message  = FALSE
)
```

## Installation

```{r}
# install.packages("pak")
pak::pak("Jeremie-Beucler/baserater")
```

## Download data

```{r}
library(baserater)

database <- download_data("database")             # full base‑rate set
ratings   <- download_data("validation_ratings")  # 100 human‑rated items
```

## Generate scores with an LLM

```{r}
new_scores <- hf_typicality(
  groups       = c("nurse", "clown"),
  descriptions = c("caring", "funny"),
  model        = "meta-llama/Llama-3.1-8B-Instruct",
  hf_token     = "your_token_here",
  n            = 10,
  min_valid    = 8,
  matrix       = FALSE
)
```

## Evaluate model predictions

```{r}
evaluate_external_ratings(new_scores)
```

## Build a base-rate item dataset

```{r}
gpt4_matrix    <- download_data("similarity_matrix_gpt4")
base_rate_tbl  <- extract_base_rate_items(gpt4_matrix)
```

## More

Full documentation: https://jeremie-beucler.github.io/baserater/

Forthcoming paper: *Using Large Language Models to Estimate Belief Strength in Reasoning* (Beucler et al.)

## License

GPL-3
